
<summary>Automated Data Query and Retrieval System</summary>

This system allows users to query and retrieve data from a MongoDB database using natural language inputs, leveraging offline (free & open-source) Large Language Models (LLMs). The system supports loading data from CSV files into MongoDB, generating dynamic MongoDB queries based on user input, and presenting the retrieved data in a human-readable format or saving it to a new CSV file.

#Features
CSV Data Ingestion: Load data from a CSV file into a MongoDB collection.
Dynamic Query Generation: Utilize an LLM to generate syntactically and logically sound MongoDB queries from natural language user inputs.
Data Retrieval & Presentation: Execute generated MongoDB queries and display the results or save them to a new CSV file.
User-Friendly Interface: Allows users to easily input column names, ask questions, and choose output preferences.
Robust Error Handling: Manages invalid user inputs, incorrect LLM-generated queries, and MongoDB connectivity issues.
Deliverables
The project deliverables include:

#Python Scripts:
An end-to-end Python script combining all functionalities: CSV data loading, dynamic query generation and execution, and data presentation/saving.
Separate modules/functions within the script for loading CSV data into MongoDB, generating/executing MongoDB queries using an LLM, and displaying/saving retrieved data.
Documentation:
This README.md file with detailed setup and usage instructions.
In-code comments and explanations for key functions.
Test Case Output:
Demonstration of the system's functionality, including edge cases and error scenarios.
Output for the three specified test cases in CSV format.
Output Data:
A sample CSV file for testing the system.
A Queries_generated.txt file containing the MongoDB queries generated by the LLM for each test case.
Setup and Installation
Follow these steps to set up and run the system:

#Prerequisites:

Python 3.x installed.
MongoDB installed and running.
pip (Python package installer).
Clone the Repository (or download the script):

Bash

git clone <repository_url>
cd <repository_directory>
(Replace <repository_url> and <repository_directory> with your actual repository information)

Install Dependencies:
Install the required Python libraries using pip:

Bash

pip install pandas pymongo langchain llama_index  # Add any other necessary libraries like a specific LLM library
pandas: For CSV data handling.
pymongo: For interacting with MongoDB.
langchain: For orchestrating LLM interactions.
llama_index: For data indexing and retrieval with LLMs.
Note: You will also need to install the specific open-source LLM library you choose to use (e.g., transformers for a local Hugging Face model, ollama for Ollama models, etc.).
MongoDB Configuration:

Ensure your MongoDB instance is running.
The script will connect to your MongoDB instance. You might need to configure the MongoDB connection URI in the script if it's not running on the default localhost:27017.
Offline LLM Setup:

Choose and set up your preferred free and open-source LLM. This might involve:
Downloading the model weights.
Using a library like transformers to load and run the model locally.
Setting up a local LLM server (e.g., Ollama, LocalGPT).
Ensure the LLM is accessible by your Python script. The script will need to be configured to interact with your chosen LLM.
Usage
Prepare your CSV Data:
Place your input CSV file (e.g., products.csv) in the same directory as the Python script. A sample CSV file should be included in the deliverables for testing purposes.

Run the Main Script:
Execute the primary Python script from your terminal:

Bash

python your_main_script_name.py
(Replace your_main_script_name.py with the actual name of your combined Python script).

Follow On-Screen Prompts:
The system will guide you through the process:

Load CSV to MongoDB: The script will first prompt you to confirm loading the CSV data into MongoDB. It will automatically create a new collection for the data.
Enter CSV Column Header: You will be asked to input a CSV column header relevant to your query (e.g., "Price", "Category").
Ask a Question: You can then ask a natural language question related to the data, incorporating the column header if desired (e.g., "What are the products with a price greater than $50?", "List all products in the Electronics category.").
Choose Output Option: You will be given the option to:
Display the retrieved data in the console.
Save the retrieved data to a new CSV file (e.g., test_case1.csv).
Example Walkthrough
Let's assume you have a products.csv file with columns like Product ID, Name, Price, Category, Rating, Reviews, Brand, In Stock, Launch Date, Discount.

Run the script: python your_main_script_name.py
The script will load products.csv into a MongoDB collection (e.g., products_collection).
When prompted for a column header, you might enter: Rating
When asked for a question, you could type: Find all products with a rating below 4.5 that have more than 200 reviews and are offered by the brand 'Nike' or 'Sony'. 
The LLM will generate a MongoDB query (e.g., db.products_collection.find({"Rating": {"$lt": 4.5}, "Reviews": {"$gt": 200}, "Brand": {"$in": ["Nike", "Sony"]}})). This query will be saved to Queries_generated.txt.
The system will execute this query, retrieve the data, and prompt you to display it or save it as test_case1.csv.
Test Cases
The system has been tested against the following scenarios:

Find all products with a rating below 4.5 that have more than 200 reviews and are offered by the brand 'Nike' or 'Sony'. 
Expected Output: A CSV file (e.g., test_case1.csv) containing products matching these criteria.
Generated Query: Will be saved in Queries_generated.txt.
Which products in the Electronics category have a rating of 4.5 or higher and are in stock? 
Expected Output: A CSV file (e.g., test_case2.csv) containing products from the Electronics category meeting the rating and stock requirements.
Generated Query: Will be saved in Queries_generated.txt.
List products launched after January 1, 2022, in the Home & Kitchen or Sports categories with a discount of 10% or more, sorted by price in descending order. 
Expected Output: A CSV file (e.g., test_case3.csv) listing relevant products, sorted by price in descending order.
Generated Query: Will be saved in Queries_generated.txt.
Error Handling
The system includes error handling for:

Invalid or non-existent column names provided by the user.
Incorrect or incomplete queries generated by the LLM.
Issues with MongoDB connectivity or data retrieval.
Additional Considerations
Security: Ensure secure interaction with the LLM and MongoDB, especially in a production environment.
Efficiency: The system is optimized for performance, particularly when handling large CSV files or complex queries.
Scalability: The architecture considers scalability for handling multiple CSV files, larger datasets, or more complex user queries.
Documentation: Comprehensive documentation is provided, including setup and installation instructions.
